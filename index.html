<!doctype html>
<html>
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="./output.css" rel="stylesheet">
  </head>

  <body class="flex items-top justify-center min-h-screen bg-gray-50 font-primary font-extralight">
    <div class="max-w-5xl mt-4 space-y-8">
      <header class="my-8">
        <span class="text-3xl font-light text-start">
          Effective and Traceable Speech Synthesis for Low-Resource Languages
        </span>
      </header>
  
      <div class="flex flex-col">
        <div class="flex space-x-2">
          <span class="text-lg font-light">Supervisor:</span>
          <span class="text-lg">Mirko Marras</span>
        </div>

        <div class="flex space-x-2">
          <span class="text-lg font-light">Co-Supervisor:</span>
          <span class="text-lg">Marco Manolo Manca</span>
        </div>

        <!-- ADD DELIMITER -->

        <div class="flex space-x-2 mt-4">
          <span class="text-lg font-light">Candidate:</span>
          <span class="text-lg">Gabriele Carta</span>
        </div>
      </div>
      
      <!-- ADD DELIMITER -->
      
      <div class="flex flex-col space-y-2">
        <span class="text-2xl font-light">Abstract</span>
        <span class="text-lg text-justify">Recent advances in speech synthesis have led to highly expressive and intelligible text-to-speech systems. However, these developments have predominantly targeted high-resource languages, leaving low-resource languages underrepresented and further widening the digital divide. In this thesis, we address this disparity by focusing on Sardinian, a language spoken on the island of Sardinia, characterized by limited digital resources and significant dialectal variation. We present a reproducible pipeline for speech data processing, including cleaning, alignment, and segmentation, and fine-tune two state-of-the-art multilingual text-to-speech models (XTTS-v2 and F5TTS) on two distinct Sardinian corpora. The resulting models are evaluated using established objective metrics to assess synthesis quality across dialectal varieties. Beyond synthesis performance, we examine the ethical implications associated with the uncontrolled use of generative speech technologies, particularly the risks of voice impersonation and misinformation. To address these concerns, we integrate an acoustic watermarking mechanism into the generated speech, enabling verifiable traceability and reliable differentiation between synthetic and human speech. Our findings contribute a principled and generalizable framework for responsible speech synthesis in low-resource contexts, with implications for both technological development and ethical deployment.</span>
      </div>

      <!-- ADD DELIMITER -->

      <div class="flex flex-col space-y-2">
        <span class="text-2xl font-light">Audio Samples</span>
      </div>
    </div>
  </body>

</html>